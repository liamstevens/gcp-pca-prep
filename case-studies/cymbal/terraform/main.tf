#### This was generated by Gemini in the spirit of using GenAI to do things.
#### It was based on the solution architecture provided to it, but it doesn't guarantee that it will work out of the box.
#### Feel free to try it out, but exercise critical thinking.


# --- Provider Configuration ---
terraform {
  required_providers {
    google = {
      source  = "hashicorp/google"
      version = ">= 4.50.0" # Use a recent version
    }
  }
  required_version = ">= 1.0"
}

provider "google" {
  project = var.project_id
  region  = var.region
}

# --- Variable Definitions ---
variable "project_id" {
  description = "The GCP project ID."
  type        = string
}

variable "region" {
  description = "The primary GCP region for resources."
  type        = string
  default     = "us-central1"
}

variable "zones" {
  description = "The zones for regional resources like GKE."
  type        = list(string)
  default     = ["us-central1-a", "us-central1-b", "us-central1-c"]
}

variable "gke_cluster_name" {
  description = "Name for the GKE cluster."
  type        = string
  default     = "cymbal-primary-cluster"
}

variable "gke_machine_type" {
  description = "Machine type for GKE nodes."
  type        = string
  default     = "e2-standard-4" # General purpose, adjust as needed
}

variable "cloudsql_mysql_tier" {
  description = "Machine type for the Cloud SQL MySQL instance."
  type        = string
  default     = "db-f1-micro" # Example tier, adjust for production
}

variable "cloudsql_mssql_tier" {
  description = "Machine type for the Cloud SQL SQL Server instance."
  type        = string
  default     = "db-custom-1-3840" # Example tier, adjust for production
}

variable "memorystore_redis_tier" {
  description = "Tier for the Memorystore Redis instance."
  type        = string
  default     = "BASIC" # BASIC or STANDARD_HA
}

variable "memorystore_redis_size_gb" {
  description = "Size of the Memorystore Redis instance in GB."
  type        = number
  default     = 1
}

variable "storage_bucket_name" {
  description = "Name for the primary Cloud Storage bucket."
  type        = string
  default     = "" # Keep empty to use project ID based naming, or set explicitly
}

variable "bq_dataset_name" {
  description = "Name for the BigQuery dataset."
  type        = string
  default     = "cymbal_analytics"
}

variable "dialogflow_agent_name" {
  description = "Display name for the Dialogflow CX agent."
  type        = string
  default     = "CymbalRetailAgent"
}

variable "interconnect_attachment_name" {
  description = "Name for the Dedicated Interconnect VLAN attachment."
  type        = string
  default     = "cymbal-vlan-onprem"
}

variable "cloud_router_name" {
  description = "Name for the Cloud Router needed for Interconnect BGP."
  type        = string
  default     = "cymbal-router-onprem"
}

# --- Networking ---

# Using the default VPC for simplicity, but a custom VPC is recommended for production.
# Ensure the default VPC exists or create a custom one using the google_compute_network resource.

# Cloud Router for BGP peering over Interconnect
resource "google_compute_router" "router" {
  name    = var.cloud_router_name
  network = "default" # Assumes default VPC, change if using custom
  region  = var.region
  bgp {
    asn = 64514 # Example Google side ASN
  }
}

# Placeholder for Dedicated Interconnect VLAN attachment
# Actual creation requires an existing Interconnect connection provisioned via Cloud Console/API first.
# This assumes you have the Interconnect resource link (`google_compute_interconnect.interconnect.self_link`)
/*
resource "google_compute_interconnect_attachment" "on_prem_attachment" {
  name                     = var.interconnect_attachment_name
  region                   = var.region
  router                   = google_compute_router.router.id
  # interconnect           = google_compute_interconnect.interconnect.self_link # Link to your Interconnect resource
  type                     = "PARTNER" # Or DEDICATED
  # edge_availability_domain = "AVAILABILITY_DOMAIN_1" # Or DOMAIN_2
  # vlan_tag8021q            = 1000 # Example VLAN tag
  # candidate_subnets        = ["169.254.x.x/29"] # Address range for BGP peering
}
*/
# Note: Provisioning Dedicated Interconnect itself is outside the scope of typical Terraform setup
# as it involves physical connections. You usually create VLAN attachments on existing connections.

# --- Global Load Balancer (Placeholder - Requires Backend Services, URL Maps etc.) ---

# This setup requires more detail about your GKE services (e.g., using Ingress controller or standalone NEGs)
# Using the official Cloud Load Balancing module: https://registry.terraform.io/modules/GoogleCloudPlatform/lb-http/google/latest

/*
module "gce-lb-http" {
  source  = "GoogleCloudPlatform/lb-http/google"
  version = "~> 6.0" # Check for latest version

  project = var.project_id
  name    = "cymbal-http-lb"
  target_tags = ["http-server"] # Example, better to use Network Endpoint Groups (NEGs) with GKE

  # ssl             = true # Enable SSL
  # managed_ssl_certificate_domains = ["cymbal.example.com"] # Your domain

  # Define backend services pointing to GKE or other backends here
  backends = {
    default = {
      port        = 80
      protocol    = "HTTP"
      port_name   = "http"
      description = "Default backend service"
      enable_cdn  = false
      # group = <link-to-instance-group-or-neg> # This needs to point to your GKE services
      security_policy = null # Add Cloud Armor policy name if needed
    }
  }
}
*/
# --- Google Kubernetes Engine (GKE) ---

module "gke" {
  source                     = "terraform-google-modules/kubernetes-engine/google"
  version                    = "~> 27.0" # Check for latest module version
  project_id                 = var.project_id
  name                       = var.gke_cluster_name
  region                     = var.region
  zones                      = var.zones
  network                    = "default" # Assumes default VPC
  subnetwork                 = "default" # Assumes default subnetwork
  ip_range_pods = "10.0.0.0/16"
  ip_range_services = "10.1.0.0/16"
  http_load_balancing        = true      # Enable GCLB integration addon
  network_policy             = false     # Enable network policy (recommended for prod)
  initial_node_count         = 1
  remove_default_node_pool   = true

  node_pools = [
    {
      name           = "default-node-pool"
      machine_type   = var.gke_machine_type
      node_locations = join(",", var.zones) # Distribute across specified zones
      min_count      = 1
      max_count      = 5 # Example autoscaling limits
      auto_repair    = true
      auto_upgrade   = true
    },
  ]
}

# --- Databases ---

# Cloud SQL - MySQL
resource "google_sql_database_instance" "mysql_instance" {
  name             = "cymbal-mysql"
  database_version = "MYSQL_8_0" # Choose appropriate version
  region           = var.region
  settings {
    tier = var.cloudsql_mysql_tier
    availability_type = "REGIONAL" # For High Availability
    ip_configuration {
      ipv4_enabled    = true
      private_network = "projects/${var.project_id}/global/networks/default" # Assumes default VPC
    }
    backup_configuration {
      enabled = true
    }
  }
  deletion_protection = false # Set to true for production
}

# Cloud SQL - SQL Server
resource "google_sql_database_instance" "mssql_instance" {
  name             = "cymbal-mssql"
  database_version = "SQLSERVER_2019_STANDARD" # Choose appropriate version & edition
  region           = var.region
  root_password    = "MustBeChanged!" # Use Secret Manager in production
  settings {
    tier = var.cloudsql_mssql_tier
    availability_type = "REGIONAL" # For High Availability
     ip_configuration {
      ipv4_enabled    = true
      private_network = "projects/${var.project_id}/global/networks/default" # Assumes default VPC
    }
     backup_configuration {
      enabled = true
    }
  }
   deletion_protection = false # Set to true for production
}


# Memorystore - Redis
resource "google_redis_instance" "cache" {
  name           = "cymbal-redis-cache"
  tier           = var.memorystore_redis_tier
  memory_size_gb = var.memorystore_redis_size_gb
  region         = var.region
  authorized_network = "default" # Assumes default VPC
  redis_version  = "REDIS_6_X" # Choose appropriate version
}

# Firestore (in Native Mode - replaces Datastore for most new use cases)
# Enable Firestore API: `gcloud services enable firestore.googleapis.com`
resource "google_project_service" "firestore_api" {
  project = var.project_id
  service = "firestore.googleapis.com"
  disable_dependent_services = false
  disable_on_destroy         = false
}

# Firestore requires choosing a location and mode (Native/Datastore) via Console/gcloud for the first time.
# Terraform doesn't directly create the initial Firestore database instance.
# This resource manages the App Engine app which *hosts* Firestore.
resource "google_app_engine_application" "app" {
  project     = var.project_id
  location_id = var.region # Or a multi-region like nam5 or eur3
  database_type = "CLOUD_FIRESTORE" # Or CLOUD_DATASTORE_COMPATIBILITY
  depends_on = [google_project_service.firestore_api]
}


# --- Cloud Storage ---
locals {
  # Use project ID for bucket name if not overridden, ensure global uniqueness
  bucket_name = var.storage_bucket_name != "" ? var.storage_bucket_name : "${var.project_id}-cymbal-assets"
}

resource "google_storage_bucket" "asset_storage" {
  name          = local.bucket_name
  location      = var.region # Choose appropriate location (regional, multi-regional)
  force_destroy = false # Set to true only for non-production testing

  uniform_bucket_level_access = true

  versioning {
    enabled = true
  }

  lifecycle_rule {
    action {
      type = "Delete"
    }
    condition {
      age = 30 # Example: delete objects older than 30 days
      # with_state = "ARCHIVED" # Example condition
    }
  }
}

# --- Serverless (Cloud Functions Placeholder) ---

# Enable Cloud Functions and related APIs
resource "google_project_service" "cloudfunctions_api" {
  project = var.project_id
  service = "cloudfunctions.googleapis.com"
  disable_dependent_services = false
  disable_on_destroy         = false
}
resource "google_project_service" "cloudbuild_api_for_functions" {
  project = var.project_id
  service = "cloudbuild.googleapis.com" # Needed for building functions
  disable_dependent_services = false
  disable_on_destroy         = false
}

/*
# Example Cloud Function (requires code source)
resource "google_cloudfunctions_function" "async_task_processor" {
  name        = "cymbal-async-processor"
  description = "Processes async tasks triggered by storage uploads"
  runtime     = "python39" # Choose your runtime

  available_memory_mb   = 256
  source_archive_bucket = google_storage_bucket.asset_storage.name
  source_archive_object = "function-source.zip" # You need to upload your zipped code
  trigger_http          = false # Example: Trigger via event, not HTTP
  entry_point           = "handler" # Function entrypoint in your code

  event_trigger {
    event_type = "google.storage.object.finalize"
    resource   = google_storage_bucket.asset_storage.name
  }

  # Environment variables, VPC connector, etc. can be added here
}
*/

# --- AI / ML Services ---

# Enable Vertex AI API
resource "google_project_service" "vertex_ai_api" {
  project = var.project_id
  service = "aiplatform.googleapis.com"
  disable_dependent_services = false
  disable_on_destroy         = false
}

# Enable Text-to-Speech API
resource "google_project_service" "tts_api" {
  project = var.project_id
  service = "texttospeech.googleapis.com"
  disable_dependent_services = false
  disable_on_destroy         = false
}

# Enable Dialogflow (CCAI) API
resource "google_project_service" "dialogflow_api" {
  project = var.project_id
  service = "dialogflow.googleapis.com"
  disable_dependent_services = false
  disable_on_destroy         = false
}

# Basic Dialogflow CX Agent (CCAI)
# Note: Building flows, intents, pages etc. is done via UI or API calls, not directly in standard TF
resource "google_dialogflow_cx_agent" "cymbal_agent" {
  display_name = var.dialogflow_agent_name
  location     = "global" # Or choose a specific region like us-central1
  default_language_code = "en"
  time_zone = "America/Los_Angeles" # Choose appropriate time zone
  # description = "Cymbal Retail Virtual Agent"
  # avatar_uri = "..."

  speech_to_text_settings {
      enable_speech_adaptation = true
  }

  depends_on = [google_project_service.dialogflow_api]
}


# --- Analytics ---

# Enable BigQuery API
resource "google_project_service" "bigquery_api" {
  project = var.project_id
  service = "bigquery.googleapis.com"
  disable_dependent_services = false
  disable_on_destroy         = false
}

# BigQuery Dataset
resource "google_bigquery_dataset" "analytics_dataset" {
  dataset_id                 = var.bq_dataset_name
  friendly_name              = "Cymbal Retail Analytics"
  description                = "Dataset for storing Cymbal Retail analytics data"
  location                   = "US" # Choose location (e.g., US, EU, region like us-central1)
  delete_contents_on_destroy = false # Set to true only for non-production testing

  depends_on = [google_project_service.bigquery_api]
}

# --- Outputs (Examples) ---

output "gke_cluster_name" {
  value = module.gke.name
}

output "gke_endpoint" {
  value = module.gke.endpoint
  sensitive = true
}

output "cloud_storage_bucket_url" {
  value = "gs://${google_storage_bucket.asset_storage.name}"
}

output "mysql_instance_connection_name" {
  value = google_sql_database_instance.mysql_instance.connection_name
}

output "mssql_instance_connection_name" {
  value = google_sql_database_instance.mssql_instance.connection_name
}

output "redis_instance_host" {
  value = google_redis_instance.cache.host
}

output "bigquery_dataset_id" {
  value = google_bigquery_dataset.analytics_dataset.dataset_id
}

output "dialogflow_agent_name" {
  value = google_dialogflow_cx_agent.cymbal_agent.name # This is the resource name, not display name
}